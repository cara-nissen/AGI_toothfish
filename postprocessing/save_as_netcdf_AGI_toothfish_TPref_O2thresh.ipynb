{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get Tpref & O2thresh for each species\n",
    "# need to have enough memory (some fields are big), 50GB worked\n",
    "# save as netcdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_ipython().system(u'jupyter nbconvert --to=python plot_AGI_toothfish_testing.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from netCDF4 import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----\n",
    "# Collection of notes:\n",
    "#\n",
    "# excluded two species for now (see Anne's mail): \n",
    "# 1) Antimora rostrata: don't have the habitat file (habitat outside of SO) -> have it now, just not yet included\n",
    "# 2) Macrourus whitsoni (only have Tpref, but not o2thresh & AGIcrit) -> in the making\n",
    "#\n",
    "# For some species, the variable in AGI_crit file is actually called \"o2thresh\"\n",
    "#  I think the values are correct (at least the order of magnitude suggests that they are indeed AGI values), \n",
    "#  but to be double-checked\n",
    "#  The follwoing files/species are affected: \n",
    "#      AGIcrit_Chaenodraco_wilsoni.nc\n",
    "#      AGIcrit_Lepidonotothen_squamifrons.nc\n",
    "#      AGIcrit_Notothenia_rossii.nc\n",
    "#      AGIcrit_Chionobathyscus_dewitti.nc\n",
    "#      AGIcrit_Muraenolepis_microps.nc\n",
    "#\n",
    "# Be careful: \n",
    "#  the order in which files/species are loaded e.g. for the array species_names does NOT\n",
    "#   match the order in which the species are in the lists of LWa, LWb, Linf, depth_min & depth_max\n",
    "#  As a result, I have added a line to make sure the correct index_depth_min/max are stored for each species\n",
    "#\n",
    "# python indexing: \n",
    "#  when selceting the indices index_depth_min:index_depth_max from an array, one actually does NOT include\n",
    "#   the index index_depth_max\n",
    "#  I assume that we want to include that max. depth though, so I added a \"+1\" (effectively increasing the habitat)\n",
    "#  -> that impacts the calculation of o2thresh and Tpref, wouldn't it? -> check with Anne3 \n",
    "# Note after meeting with Anne: we agreed to rather be inclusive (= keep \"+1\") to \n",
    "#    a) add more data and \n",
    "#    b) assuming that there is some uncertainty associated with the observation-based max. depth\n",
    "#\n",
    "# I had trouble making the volume calculation work when starting from the example script\n",
    "#    (lots of array dimension mismatches)\n",
    "#  I re-coded things a bit to make sure all the arrays are the same size when mutiplied\n",
    "#  I also explicitly kicked out any bathymetry nodes or nodes outside of the habitat \n",
    "#\n",
    "# AA Toothfish: it is still marked that the depth range is not correct (currently assumed to be 0-10m here, \n",
    "#   info is misisng in the table) -> check with Jilda\n",
    "#  -> that impacts the calculation of o2thresh and Tpref, wouldn't it? -> check with Anne\n",
    "#\n",
    "# As a result of all these small things, I get different AGU_crit than those stored in the nc files...\n",
    "#   to be double-checked!!\n",
    "#\n",
    "# should it be (W[i]**(1-d))/(Winf[i]**(1-d))    or     (W[i]**(1-d))/(Winf[i])  ?\n",
    "#    the PDF suggests the latter, checking Clarke2021 suggests the former (I now used the former)\n",
    "#\n",
    "#  Tpref & in-situ temp in the equation should be in Kelvin!! (otherwise I get lots of \"infinity\")\n",
    "#\n",
    "#-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Galiteuthis glacialis', 'Mesonychoteuthis hamiltoni', 'Notothenia rossii', 'Pleuragramma antarctica', 'Trematomus hansoni', 'Chaenodraco wilsoni', 'Cryodraco antarcticus', 'Kondakovia longimana', 'Trematomus eulepidotus', 'Macrourus whitsoni', 'Notothenia coriiceps', 'Neopagetopsis ionah', 'Lepidonotothen squamifrons', 'Chaenocephalus aceratus', 'Chionobathyscus dewitti', 'Muraenolepis microps', 'Bathyraja maccaini', 'Dissostichus mawsoni']\n",
      "18 species\n",
      "['Galiteuthis_glacialis', 'Mesonychoteuthis_hamiltoni', 'Notothenia_rossii', 'Pleuragramma_antarctica', 'Trematomus_hansoni', 'Chaenodraco_wilsoni', 'Cryodraco_antarcticus', 'Kondakovia_longimana', 'Trematomus_eulepidotus', 'Macrourus_whitsoni', 'Notothenia_coriiceps', 'Neopagetopsis_ionah', 'Lepidonotothen_squamifrons', 'Chaenocephalus_aceratus', 'Chionobathyscus_dewitti', 'Muraenolepis_microps', 'Bathyraja_maccaini', 'Dissostichus_mawsoni']\n"
     ]
    }
   ],
   "source": [
    "#-----\n",
    "# based on python code provided by Anne\n",
    "#-----\n",
    "\n",
    "basepath=\"/work/ollie/ncara/fesom/fesom-1.4-recom/HLRN/AGI_toothfish_project/\" \n",
    "no_species=18 # exclude Antimora_rostrata \n",
    "\n",
    "# Init\n",
    "species_names         = [None] * no_species # empty list\n",
    "species_names_        = [None] * no_species # empty list\n",
    "habitat_file_names    = [None] * no_species # empty list\n",
    "\n",
    "habitat_files = Path(basepath + \"updated_habitat_files/\").glob('*_boolean.nc')  # updated habitat files, Nov 2022!!!!!!\n",
    "#habitat_files = Path(basepath + \"share/\").glob('*_boolean.nc') \n",
    "# Note: I changed name of file of Antimora_rostrata to *boolean2.nc, so that it won't be included here\n",
    "for ifile,file in enumerate(habitat_files):   \n",
    "    habitat_file_names[ifile]    = str(file)\n",
    "    # Get the species name from the full pathname with a space between\n",
    "    species_names[ifile]  = '_'.join(os.path.basename(file).split('_')[:-2]).replace('_',' ') \n",
    "    if not species_names[ifile] in ['Galiteuthis glacialis','Mesonychoteuthis hamiltoni','Kondakovia longimana']:\n",
    "        species_names[ifile] = species_names[ifile][8:] # get rid of \"Default\" or \"Reviewed\"\n",
    "    if species_names[ifile][0].isspace():  # get rid of white space if there is any\n",
    "        species_names[ifile] = species_names[ifile][1:]\n",
    "    if species_names[ifile] in ['Chionobathyscus dewitti All Suitable Habitat']:\n",
    "        species_names[ifile] = species_names[ifile][0:23]\n",
    "    # Get the species name from the full pathname with _ in it\n",
    "    species_names_[ifile] = species_names[ifile].replace(' ','_')  #'_'.join(os.path.basename(file).split('_')[:-2]) \n",
    "\n",
    "#print(habitat_file_names)\n",
    "print(species_names)\n",
    "print(len(species_names),'species')\n",
    "print(species_names_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----\n",
    "# Species information needed for calculation AGI\n",
    "#----\n",
    "\n",
    "# define order of species as contained in depth_min, LWa etc.\n",
    "species_list = ['Cryodraco antarcticus','Neopagetopsis ionah','Trematomus eulepidotus',\\\n",
    "               'Trematomus hansoni','Bathyraja maccaini','Chaenocephalus aceratus',\\\n",
    "               'Notothenia coriiceps','Pleuragramma antarctica','Dissostichus mawsoni',\\\n",
    "                'Macrourus whitsoni',\\\n",
    "               'Lepidonotothen squamifrons','Notothenia rossii','Muraenolepis microps',\\\n",
    "               'Chaenodraco wilsoni','Chionobathyscus dewitti',\\\n",
    "               'Galiteuthis glacialis','Mesonychoteuthis hamiltoni','Kondakovia longimana']\n",
    "# excluded the following species for now: \n",
    "# 1) Antimora rostrata: don't have the habitat file (habitat outside of SO)\n",
    "\n",
    "# Minimum depth of occurence (meter)\n",
    "depth_min     = [None] * len(species_names) # Initialize\n",
    "depth_min[0]  = 90   # 'Cryodraco antarcticus'\n",
    "depth_min[1]  = 20   #'Neopagetopsis ionah'\n",
    "depth_min[2]  = 0    # 'Trematomus eulepidotus'\n",
    "depth_min[3]  = 6    # 'Trematomus hansoni'\n",
    "depth_min[4]  = 167  # 'Bathyraja maccaini'\n",
    "depth_min[5]  = 0    # 'Chaenocephalus aceratus'\n",
    "depth_min[6]  = 0    # 'Notothenia coriiceps'\n",
    "depth_min[7]  = 0    # 'Pleuragramma antarctica'\n",
    "depth_min[8]  = 0    # 'Dissostichus mawsoni' ## Assume a wide range for toothfish (max. overlap with prey) ##\n",
    "depth_min[9]  = 400  # 'Macrourus whitsoni'\n",
    "depth_min[10] = 10   # 'Lepidonotothen squamifrons'\n",
    "#depth_min[11] = 350  # 'Antimora rostrata'\n",
    "depth_min[11] = 0    # 'Notothenia rossii'\n",
    "depth_min[12] = 10   # 'Muraenolepis microps'\n",
    "depth_min[13] = 250  # 'Chaenodraco wilsoni'\n",
    "depth_min[14] = 500  # 'Chionobathyscus dewitti'\n",
    "depth_min[15] = 200   #'Galiteuthis glacialis'\n",
    "depth_min[16] = 200   # 'Mesonychoteuthis hamiltoni'\n",
    "depth_min[17] = 500   # 'Kondakovia longimana'\n",
    "\n",
    "# Maximum depth of occurence (meter)\n",
    "depth_max     = [None] * len(species_names) # Initialize\n",
    "depth_max[0]  = 600  # 'Cryodraco antarcticus'\n",
    "depth_max[1]  = 900  #'Neopagetopsis ionah'\n",
    "depth_max[2]  = 700  # 'Trematomus eulepidotus'\n",
    "depth_max[3]  = 549  # 'Trematomus hansoni'\n",
    "depth_max[4]  = 500  # 'Bathyraja maccaini'\n",
    "depth_max[5]  = 770  # 'Chaenocephalus aceratus'\n",
    "depth_max[6]  = 550  # 'Notothenia coriiceps'\n",
    "depth_max[7]  = 728  # 'Pleuragramma antarctica'\n",
    "depth_max[8]  = 2210   # 'Dissostichus mawsoni' ## Assume a wide range for toothfish (max. overlap with prey) ##\n",
    "depth_max[9]  = 3185 # 'Macrourus whitsoni'\n",
    "depth_max[10] = 900  # 'Lepidonotothen squamifrons'\n",
    "#depth_max[11] = 3000 # 'Antimora rostrata'\n",
    "depth_max[11] = 1000 # 'Notothenia rossii'\n",
    "depth_max[12] = 1600 # 'Muraenolepis microps'\n",
    "depth_max[13] = 800  # 'Chaenodraco wilsoni'\n",
    "depth_max[14] = 2000 # 'Chionobathyscus dewitti'\n",
    "depth_max[15] = 2500   #'Galiteuthis glacialis'\n",
    "depth_max[16] =  600  # 'Mesonychoteuthis hamiltoni'\n",
    "depth_max[17] = 2000   # 'Kondakovia longimana'\n",
    "\n",
    "#---\n",
    "# NOTE Jan 2023: this info below is not needed anymore with the new AGI formulation!\n",
    "#----\n",
    "# LWa extracted 21.07.2022 from FishBase\n",
    "LWa     = [None] * len(species_names) # Initialize\n",
    "LWa[0]  = 0.0007  # 'Cryodraco antarcticus'\n",
    "LWa[1]  = 0.01863  #'Neopagetopsis ionah'\n",
    "LWa[2]  = 0.0042  # 'Trematomus eulepidotus'\n",
    "LWa[3]  = 0.0021  # 'Trematomus hansoni'\n",
    "LWa[4]  = 0.00477  # 'Bathyraja maccaini'\n",
    "LWa[5]  = 0.0006 # 'Chaenocephalus aceratus'\n",
    "LWa[6]  = 0.0132  # 'Notothenia coriiceps'\n",
    "LWa[7]  = 0.0019  # 'Pleuragramma antarctica'\n",
    "LWa[8]  = 0.0045   # 'Dissostichus mawsoni'\n",
    "LWa[9]  = 0.0135 # 'Macrourus whitsoni'\n",
    "LWa[10] = 0.0027  # 'Lepidonotothen squamifrons'\n",
    "#LWa[11] = 0.001     # 'Antimora rostrata'\n",
    "LWa[11] = 0.0093 # 'Notothenia rossii'\n",
    "LWa[12] = 0.00437 # 'Muraenolepis microps'\n",
    "LWa[13] = 0.0005  # 'Chaenodraco wilsoni'\n",
    "LWa[14] = 0.0012 # 'Chionobathyscus dewitti'\n",
    "\n",
    "# LWb extracted 21.07.2022 from FishBase\n",
    "LWb     = [None] * len(species_names) # Initialize\n",
    "LWb[0]  = 3.51  # 'Cryodraco antarcticus'\n",
    "LWb[1]  = 2.762  #'Neopagetopsis ionah'\n",
    "LWb[2]  = 3.32  # 'Trematomus eulepidotus'\n",
    "LWb[3]  = 3.52  # 'Trematomus hansoni'\n",
    "LWb[4]  = 3.162  # 'Bathyraja maccaini'\n",
    "LWb[5]  = 3.63  # 'Chaenocephalus aceratus'\n",
    "LWb[6]  = 3.09  # 'Notothenia coriiceps'\n",
    "LWb[7]  = 3.41  # 'Pleuragramma antarctica'\n",
    "LWb[8]  = 3.24   # 'Dissostichus mawsoni'\n",
    "LWb[9]  = 3.15 # 'Macrourus whitsoni'\n",
    "LWb[10] = 3.41  # 'Lepidonotothen squamifrons'\n",
    "#LWb[11] = 3.52   # 'Antimora rostrata'\n",
    "LWb[11] = 3.07 # 'Notothenia rossii'\n",
    "LWb[12] = 3.11 # 'Muraenolepis microps'\n",
    "LWb[13] = 3.79  # 'Chaenodraco wilsoni'\n",
    "LWb[14] = 3.5 # 'Chionobathyscus dewitti'\n",
    "\n",
    "# Linf extracted 21.07.2022 from FishBase\n",
    "# * Linf estimated from Lmax using Froese and Binohlan (2000) Eq. (5).\n",
    "Linf     = [None] * len(species_names) # Initialize\n",
    "Linf[0]  = 50.66374052  # 'Cryodraco antarcticus'*\n",
    "Linf[1]  = 58.12886422  #'Neopagetopsis ionah'*\n",
    "Linf[2]  = 26.5  # 'Trematomus eulepidotus'\n",
    "Linf[3]  = 36.5  # 'Trematomus hansoni'\n",
    "Linf[4]  = 123.061517  # 'Bathyraja maccaini'*\n",
    "Linf[5]  = 70.4  # 'Chaenocephalus aceratus'\n",
    "Linf[6]  = 62  # 'Notothenia coriiceps'\n",
    "Linf[7]  = 25.1  # 'Pleuragramma antarctica'\n",
    "Linf[8]  = 183   # 'Dissostichus mawsoni'\n",
    "Linf[9]  = 92 # 'Macrourus whitsoni'\n",
    "Linf[10] = 56.7  # 'Lepidonotothen squamifrons'\n",
    "#Linf[11] = 66   # 'Antimora rostrata'\n",
    "Linf[11] = 87 # 'Notothenia rossii'\n",
    "Linf[12] = 36.60305736 # 'Muraenolepis microps'*\n",
    "Linf[13] = 44.82252387  # 'Chaenodraco wilsoni'*\n",
    "Linf[14] = 62.21264207 # 'Chionobathyscus dewitti'*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----\n",
    "# get indices of depth levels of species\n",
    "#----\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "file_mesh = '/work/ollie/ncara/fesom/fesom-1.4-recom/HLRN/files_toothfish_project_AGI/Mesh_ancillary_information_v20220919.nc'\n",
    "data_levels = xr.open_dataset(file_mesh)\n",
    "levels      = data_levels['depth'].values # 88 levels\n",
    "data_levels.close()\n",
    "\n",
    "index_min_depth     = [None] * len(species_names) # Initialize\n",
    "index_max_depth     = [None] * len(species_names) # Initialize\n",
    "\n",
    "for i,name in enumerate(species_names):\n",
    "    # Note Cara: order of entries in depth_min etc. is not alphabetical!!!!\n",
    "    # here, I have adapted the index from \"i\" to \"iii\" to read in the correct depth ranges\n",
    "    # for the current species\n",
    "    iii = species_list.index(species_names[i]) # get index of current species as contained in depth_min etc.\n",
    "    index_min_depth[i] = find_nearest(levels,depth_min[iii])\n",
    "    index_max_depth[i] = find_nearest(levels,depth_max[iii])\n",
    "    # now, index_min_depth should contain the correct values according to alphabetical order as looped over\n",
    "    # NOTE: given how python is indexing, I think I then need to index over index_min_depth:index_max_depth+1\n",
    "    # (was index_min_depth:index_max_depth before)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----\n",
    "# as a test:\n",
    "# calculate AGI for monthly clim\n",
    "# is 10% of habitat below AGI_crit?\n",
    "#-----\n",
    "\n",
    "# constants\n",
    "d = 0.7 # n.d.; metabolic scaling coefficient\n",
    "j1 = 4500 # K; \"Anabolism activation energy divided by Boltzmann constant\" (Clarke2021)\n",
    "j2 = 8000 # K; \"Catabolism activation energy divided by Boltzmann constant\" (Clarke2021)\n",
    "j_diff = j2-j1\n",
    "# from Clarke2021: \"Somatic (or biomass) growth can be expressed as the difference between anabolism and catabolism\"\n",
    "\n",
    "read_Annes_values = False\n",
    "if read_Annes_values:\n",
    "    # Init\n",
    "    AGI_crit = [None] * no_species # empty list\n",
    "    o2thresh = [None] * no_species # empty list\n",
    "    TPref    = [None] * no_species # empty list\n",
    "\n",
    "    # read in AGI_crit that Anne has calculated\n",
    "    #files = Path(basepath + \"thresholds/\").glob('AGIcrit*') \n",
    "    #for ifile,file in enumerate(files):   \n",
    "    for ii in range(0,len(species_names)):\n",
    "        file = 'AGIcrit_'+species_names_[ii]+'.nc'\n",
    "        #print(file)\n",
    "        ff     = xr.open_dataset(basepath+'thresholds/'+file)\n",
    "        try:\n",
    "            AGI_crit[ii]        = ff['AGIcrit'].values[0][0]\n",
    "        except: # for some, the variable name is wrong (values seem ok)\n",
    "            print(file)\n",
    "            AGI_crit[ii]        = ff['o2thresh'].values[0][0] # in some files, variable is wrongly labeled\n",
    "        ff.close()\n",
    "\n",
    "    # read in o2thresh that Anne has calculated\n",
    "    #files = Path(basepath + \"thresholds/\").glob('o2thresh*') \n",
    "    #for ifile,file in enumerate(files):  \n",
    "    for ii in range(0,len(species_names)):\n",
    "        file = 'o2thresh_'+species_names_[ii]+'.nc'\n",
    "        ff     = xr.open_dataset(basepath+'thresholds/'+file)\n",
    "        o2thresh[ii]        = ff['o2thresh'].values[0][0]\n",
    "        ff.close()\n",
    "\n",
    "    # read in TPref that Anne has calculated\n",
    "    #files = Path(basepath + \"thresholds/\").glob('Tpref*') \n",
    "    #for ifile,file in enumerate(files):   \n",
    "    #    ff     = xr.open_dataset(file)\n",
    "    for ii in range(0,len(species_names)):\n",
    "        file = 'Tpref_'+species_names_[ii]+'.nc'\n",
    "        ff     = xr.open_dataset(basepath+'thresholds/'+file)\n",
    "        TPref[ii]        = ff['Tpref'].values[0][0]\n",
    "        ff.close()\n",
    "\n",
    "#-----\n",
    "# NOTE that order of species in LWa etc is not the same as in \"species_names\"\n",
    "# account for that further down!!!!\n",
    "#-----\n",
    "# UPDATE Jan 2023: the info below is not needed anymore with updated calculation of AGI\n",
    "# calculate Winf and W for each species\n",
    "#Winf = np.asarray(LWa)*(np.asarray(Linf)**np.asarray(LWb))\n",
    "#W    = (1./3.)*Winf\n",
    "#print('Winf:',Winf)\n",
    "if read_Annes_values:\n",
    "    print('AGI_crit:',AGI_crit)\n",
    "    print('o2thresh:',o2thresh)\n",
    "    print('TPref:',TPref)\n",
    "\n",
    "#--------\n",
    "# NOTE: I don't think the order provided in LWa,LWb & Linf matches the order in which AGIcrit etc are loaded here!\n",
    "# careful when indexing\n",
    "# -> see above for finding the indices for the depth range!\n",
    "#--------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tpref_Galiteuthis_glacialis.nc\n",
      "Tpref_Mesonychoteuthis_hamiltoni.nc\n",
      "Tpref_Notothenia_rossii.nc\n",
      "Tpref_Pleuragramma_antarctica.nc\n",
      "Tpref_Trematomus_hansoni.nc\n",
      "Tpref_Chaenodraco_wilsoni.nc\n",
      "Tpref_Cryodraco_antarcticus.nc\n",
      "Tpref_Kondakovia_longimana.nc\n",
      "Tpref_Trematomus_eulepidotus.nc\n",
      "Tpref_Macrourus_whitsoni.nc\n",
      "Tpref_Notothenia_coriiceps.nc\n",
      "Tpref_Neopagetopsis_ionah.nc\n",
      "Tpref_Lepidonotothen_squamifrons.nc\n",
      "Tpref_Chaenocephalus_aceratus.nc\n",
      "Tpref_Chionobathyscus_dewitti.nc\n",
      "Tpref_Muraenolepis_microps.nc\n",
      "Tpref_Bathyraja_maccaini.nc\n",
      "Tpref_Dissostichus_mawsoni.nc\n",
      "['Galiteuthis glacialis', 'Mesonychoteuthis hamiltoni', 'Notothenia rossii', 'Pleuragramma antarctica', 'Trematomus hansoni', 'Chaenodraco wilsoni', 'Cryodraco antarcticus', 'Kondakovia longimana', 'Trematomus eulepidotus', 'Macrourus whitsoni', 'Notothenia coriiceps', 'Neopagetopsis ionah', 'Lepidonotothen squamifrons', 'Chaenocephalus aceratus', 'Chionobathyscus dewitti', 'Muraenolepis microps', 'Bathyraja maccaini', 'Dissostichus mawsoni']\n"
     ]
    }
   ],
   "source": [
    "for ii in range(0,len(species_names)):\n",
    "    file = 'Tpref_'+species_names_[ii]+'.nc'  \n",
    "    print(file)\n",
    "    \n",
    "print(species_names)\n",
    "    \n",
    "#species_list = ['Cryodraco antarcticus','Neopagetopsis ionah','Trematomus eulepidotus',\\\n",
    "#               'Trematomus hansoni','Bathyraja maccaini','Chaenocephalus aceratus',\\\n",
    "#               'Notothenia coriiceps','Pleuragramma antarctica','Dissostichus mawsoni',\\\n",
    "#               'Lepidonotothen squamifrons','Notothenia rossii','Muraenolepis microps',\\\n",
    "#               'Chaenodraco wilsoni','Chionobathyscus dewitti']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88, 360, 1440)\n",
      "(12, 88, 360, 1440)\n",
      "(12, 88, 360, 1440)\n"
     ]
    }
   ],
   "source": [
    "#-----\n",
    "# calculate AGI\n",
    "# part I: load pO2 & t_insitu monthly climatologies\n",
    "#-----\n",
    "\n",
    "path1 = '/work/ollie/ncara/fesom/fesom-1.4-recom/HLRN/files_toothfish_project_AGI/simAssp585_monthly/'\n",
    "\n",
    "# pO2 data (mbar)\n",
    "file_pO2   = path1+'/pO2_fesom_simA_monthly_clim_1995_2014_v2.nc'\n",
    "data_pO2   = xr.open_dataset(file_pO2)\n",
    "pO2        = data_pO2['pO2'].values\n",
    "data_pO2.close()\n",
    "\n",
    "# T insitu (deg C)\n",
    "file_t_insitu   = path1+'/t_insitu_fesom_simA_monthly_clim_1995_2014_v2.nc'\n",
    "data_t_insitu   = xr.open_dataset(file_t_insitu)\n",
    "t_insitu        = data_t_insitu['t_insitu'].values\n",
    "data_t_insitu.close()\n",
    "\n",
    "# volume data \n",
    "data_vol   = xr.open_dataset(file_mesh)\n",
    "vol        = data_vol['volume']\n",
    "data_vol.close()\n",
    "\n",
    "print(vol.shape)\n",
    "print(t_insitu.shape)\n",
    "print(pO2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------\n",
    "# weighted quantile function\n",
    "# from here: https://stackoverflow.com/questions/21844024/weighted-percentile-using-numpy\n",
    "#------\n",
    "########\n",
    "# to be double-check carefully! \n",
    "########\n",
    "\n",
    "def weighted_quantile(values, quantiles, sample_weight=None, \n",
    "                      values_sorted=False, old_style=False):\n",
    "    \"\"\" Very close to numpy.percentile, but supports weights.\n",
    "    NOTE: quantiles should be in [0, 1]!\n",
    "    :param values: numpy.array with data\n",
    "    :param quantiles: array-like with many quantiles needed\n",
    "    :param sample_weight: array-like of the same length as `array`\n",
    "    :param values_sorted: bool, if True, then will avoid sorting of\n",
    "        initial array\n",
    "    :param old_style: if True, will correct output to be consistent\n",
    "        with numpy.percentile.\n",
    "    :return: numpy.array with computed quantiles.\n",
    "    \"\"\"\n",
    "    values = np.array(values)\n",
    "    quantiles = np.array(quantiles)\n",
    "    if sample_weight is None:\n",
    "        sample_weight = np.ones(len(values))\n",
    "    sample_weight = np.array(sample_weight)\n",
    "    assert np.all(quantiles >= 0) and np.all(quantiles <= 1), \\\n",
    "        'quantiles should be in [0, 1]'\n",
    "\n",
    "    if not values_sorted:\n",
    "        sorter = np.argsort(values)\n",
    "        values = values[sorter]\n",
    "        sample_weight = sample_weight[sorter]\n",
    "\n",
    "    weighted_quantiles = np.cumsum(sample_weight) - 0.5 * sample_weight\n",
    "    if old_style:\n",
    "        # To be convenient with numpy.percentile\n",
    "        weighted_quantiles -= weighted_quantiles[0]\n",
    "        weighted_quantiles /= weighted_quantiles[-1]\n",
    "    else:\n",
    "        weighted_quantiles /= np.sum(sample_weight)\n",
    "    return np.interp(quantiles, weighted_quantiles, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 Kondakovia longimana\n",
      "/work/ollie/ncara/fesom/fesom-1.4-recom/HLRN/AGI_toothfish_project/updated_habitat_files/Kondakovia_longimana_modelgrid_boolean.nc\n",
      "TPref: [0.64053279]\n",
      "O2thresh: [121.53898621]\n",
      "w_ratio: 0.7192230933248643\n",
      "AGI_crit calculated: 1.2658287271283182\n",
      "Create file /work/ollie/ncara/fesom/fesom-1.4-recom/HLRN/AGI_toothfish_project/new_thresholds/volume_habitat_Kondakovia_longimana_based_on_monthly_clim_1995_2014.nc\n",
      "Create file /work/ollie/ncara/fesom/fesom-1.4-recom/HLRN/AGI_toothfish_project/new_thresholds/Tpref_Kondakovia_longimana_based_on_monthly_clim_1995_2014.nc\n",
      "Create file /work/ollie/ncara/fesom/fesom-1.4-recom/HLRN/AGI_toothfish_project/new_thresholds/o2thresh_Kondakovia_longimana_based_on_monthly_clim_1995_2014.nc\n",
      "Create file /work/ollie/ncara/fesom/fesom-1.4-recom/HLRN/AGI_toothfish_project/new_thresholds/AGIcrit_Kondakovia_longimana_based_on_monthly_clim_1995_2014.nc\n",
      "Saved thresholds for Kondakovia longimana\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#-----\n",
    "# part II: calculate Tpref, O2thresh, critical AGI\n",
    "# save as netcdf\n",
    "#-----\n",
    "\n",
    "#for i,name in enumerate(species_names):\n",
    "for i in range(7,8):#len(species_names)):\n",
    "    print(i,species_names[i])\n",
    "    print(habitat_file_names[i])\n",
    "    \n",
    "    ### Get the in-habitat data for each species over the relevant depth range ###\n",
    "    file_habitat = habitat_file_names[i]\n",
    "    data_hab     = xr.open_dataset(file_habitat) # 2D habitat presence/absence data (1 for present or 0 for absent)\n",
    "    # make sure the habitat field has dimensions depth x lat x lon before applying it to the respective fields\n",
    "    num_depth = len(np.arange(index_min_depth[i],index_max_depth[i]+1,1)) \n",
    "    hab_field = np.tile(data_hab['presence'].values,(num_depth,1,1))\n",
    "    data_hab.close()\n",
    "    \n",
    "    ### select the data/volume over the relevant depth range, correct with habitat array\n",
    "    # NOTE: index_min_depth[i]:index_max_depth[i]    or.    index_min_depth[i]:index_max_depth[i]+1   ?\n",
    "    vol_inhabitat = (vol.values[index_min_depth[i]:index_max_depth[i]+1,:,:]*hab_field) \n",
    "    dataout1      = (pO2[:,index_min_depth[i]:index_max_depth[i]+1,:,:]*hab_field)\n",
    "    dataout2      = (t_insitu[:,index_min_depth[i]:index_max_depth[i]+1,:,:]*hab_field)\n",
    "    #print(dataout1.shape) # month x depth x lat x lon\n",
    "\n",
    "    # use all months\n",
    "    dataout1b = dataout1[:,:,:,:].ravel() # pO2\n",
    "    dataout2b = dataout2[:,:,:,:].ravel() # temp\n",
    "    # make sure volume array has dimensions months x depths x lat x lon before applying ravel()\n",
    "    vol_inhabitat_b = np.tile(vol_inhabitat,(12,1,1,1)).ravel() \n",
    "    \n",
    "    # make sure to only keep nodes that are available for current species\n",
    "    ind = np.where((~np.isnan(dataout1b)))[0] # every available node\n",
    "    dataout1b = dataout1b[ind]\n",
    "    dataout2b = dataout2b[ind]\n",
    "    vol_inhabitat_b = vol_inhabitat_b[ind]\n",
    "    ind = np.where((dataout1b!=0))[0] # every available node\n",
    "    dataout1b = dataout1b[ind] # pO2\n",
    "    dataout2b = dataout2b[ind] # temp\n",
    "    vol_inhabitat_b = vol_inhabitat_b[ind]\n",
    "    del ind\n",
    "    \n",
    "  #  print('Min/Max pO2 in habitat:',np.min(dataout1b),np.max(dataout1b))\n",
    "  #  print('Min/Max t insitu in habitat:',np.min(dataout2b),np.max(dataout2b))\n",
    "    \n",
    "    totalvol_inhabitat = np.nansum(vol_inhabitat_b) # total in-habitat volume (accounting for bathymetry)\n",
    "  #  print('totalvol_inhabitat (3D):',totalvol_inhabitat) \n",
    "    vol_weights = vol_inhabitat_b/np.sum(vol_inhabitat_b)\n",
    "    #print(np.sum(vol_weights)) # as a check, should be 1\n",
    "    \n",
    "    # order of species in W, Winf etc not the same as in this i-loop!\n",
    "    # correct for that here (same was done for index_min_depth and index_max_depth)\n",
    "    iii = species_list.index(species_names[i])\n",
    "    \n",
    "    #------\n",
    "    # get Tpref & O2thresh\n",
    "    #   Tpref: 50th percentile in habitat (volume weighted)\n",
    "    #   O2thresh: 10th percentile in habitat (volume weighted)\n",
    "    tpref_species    = weighted_quantile(dataout2b, [0.5], sample_weight=vol_weights)\n",
    "    o2thresh_species = weighted_quantile(dataout1b, [0.1], sample_weight=vol_weights)    \n",
    "    # from Anne's files: TPref[i],o2thresh[i]\n",
    "    if read_Annes_values:\n",
    "        print('Compare TPref from file and calculated:',TPref[i],tpref_species)\n",
    "        print('Compare O2thresh from file and calculated:',o2thresh[i],o2thresh_species)\n",
    "    else:\n",
    "        print('TPref:',tpref_species)\n",
    "        print('O2thresh:',o2thresh_species)\n",
    "    #------\n",
    "    \n",
    "    #----\n",
    "    # calculate AGIcrit: 10th percentile in habitat (volume wieghted)\n",
    "    #\n",
    "    # version used before Jan 2023\n",
    "   # w_ratio_old = (W[iii]**(1-d))/(Winf[iii]**(1-d))\n",
    "    #a1 = np.exp((j_diff/(tpref_species+273.15)) - (j_diff/(dataout2b+273.15)))\n",
    "    #\n",
    "    #AGI = dataout1b/(o2thresh_species*w_ratio*a1)\n",
    "    ##print('Min/Max AGI in 3D habitat:',np.min(AGI),np.max(AGI))\n",
    "    \n",
    "    \n",
    "    # UPDATE Jan 2023: adapt calculation of AGI to what is in Anne's paper (W, W_inf etc not needed anymore)\n",
    "    w_ratio = ((1./3.)**(1-d))\n",
    "    a1 = np.exp((j_diff/(tpref_species+273.15)) - (j_diff/(dataout2b+273.15)))\n",
    "    if read_Annes_values:\n",
    "        print('Compare w_ratio between old and new formulation:',w_ratio_old,w_ratio)\n",
    "    else:\n",
    "        print('w_ratio:',w_ratio)\n",
    "    AGI = dataout1b/(o2thresh_species*w_ratio*a1)\n",
    "    \n",
    "    \n",
    "    res = weighted_quantile(AGI, [0.1], sample_weight=vol_weights)\n",
    "    print('AGI_crit calculated:',res[0])\n",
    "    if read_Annes_values:\n",
    "        print('AGI_crit from nc file:',AGI_crit[i])    \n",
    "    \n",
    "    ind_hab = np.where(AGI>res[0])[0]\n",
    "    vol_hab = np.sum(vol_inhabitat_b[ind_hab])\n",
    "    #----\n",
    "    \n",
    "    #----\n",
    "    # save thresholds as netcdf\n",
    "    #----\n",
    "    save_as_netcdf = True\n",
    "    if save_as_netcdf:\n",
    "        savepath = '/work/ollie/ncara/fesom/fesom-1.4-recom/HLRN/AGI_toothfish_project/new_thresholds/'\n",
    "        \n",
    "        #---\n",
    "        # habitable volume, present-day\n",
    "        #---\n",
    "        netcdf_name = 'volume_habitat_'+species_names[i].replace(' ','_')+'_based_on_monthly_clim_1995_2014.nc'\n",
    "        if not os.path.exists(savepath+netcdf_name):\n",
    "            print('Create file '+savepath+netcdf_name)\n",
    "            w_nc_fid = Dataset(savepath+netcdf_name, 'w', format='NETCDF4_CLASSIC')\n",
    "            w_nc_fid.info = \"Volume in habitat above AGIcrit\" \n",
    "            w_nc_fid.note = \"calculation based on monthly data, divided by 12 here to get annual mean\" \n",
    "            w_nc_fid.author = \"Cara Nisen & Anne Moree, Nov 2022\" \n",
    "            w_nc_fid.units = \"m3\" ;\n",
    "            w_nc_fid.source_pO2    = file_pO2\n",
    "            w_nc_fid.source_Tpref    = file_t_insitu\n",
    "            w_nc_fid.script    = '/home/ollie/ncara/scripts/plot_AGI_toothfish_TPref_O2thresh_save_as_netcdf.ipynb'\n",
    "            w_nc_fid.depth_min = depth_min[iii]\n",
    "            w_nc_fid.depth_max = depth_max[iii]\n",
    "            try:\n",
    "                w_nc_fid.LWa  = LWa[iii]\n",
    "                w_nc_fid.LWb  = LWb[iii]\n",
    "                w_nc_fid.Linf = Linf[iii]\n",
    "            except: # the above info is not needed anymore with updated AGI calculation\n",
    "                pass\n",
    "            # create dimension & variable\n",
    "            w_nc_fid.createDimension('num', 1)  \n",
    "            w_nc_fid.createVariable('volume_habitat', 'f4',('num'))\n",
    "            # write variable\n",
    "            w_nc_fid.variables['volume_habitat'][:] = vol_hab/12\n",
    "            w_nc_fid.close()\n",
    "            \n",
    "        #---\n",
    "        # Tpref\n",
    "        #---\n",
    "        netcdf_name = 'Tpref_'+species_names[i].replace(' ','_')+'_based_on_monthly_clim_1995_2014.nc'\n",
    "        if not os.path.exists(savepath+netcdf_name):\n",
    "            print('Create file '+savepath+netcdf_name)\n",
    "            w_nc_fid = Dataset(savepath+netcdf_name, 'w', format='NETCDF4_CLASSIC')\n",
    "            w_nc_fid.info = \"Tpref calculated as 50th percentile from lonxlatxdepth insitu T data in-habitat, volume weighted.\" ;\n",
    "            w_nc_fid.author = \"Cara Nisen & Anne Moree, Nov 2022\" ;\n",
    "            w_nc_fid.reference = \"Tpref as described in Clarke et al. (2021)\" ;\n",
    "            w_nc_fid.units = \"C\" ;\n",
    "            w_nc_fid.method = \"50th percentile of the field using Python, weighted by volume\" ;\n",
    "            w_nc_fid.source_pO2    = file_pO2\n",
    "            w_nc_fid.source_Tpref    = file_t_insitu\n",
    "            w_nc_fid.script    = '/home/ollie/ncara/scripts/plot_AGI_toothfish_TPref_O2thresh_save_as_netcdf.ipynb'\n",
    "            w_nc_fid.depth_min = depth_min[iii]\n",
    "            w_nc_fid.depth_max = depth_max[iii]\n",
    "            try:\n",
    "                w_nc_fid.LWa  = LWa[iii]\n",
    "                w_nc_fid.LWb  = LWb[iii]\n",
    "                w_nc_fid.Linf = Linf[iii]\n",
    "            except: # the above info is not needed anymore with updated AGI calculation\n",
    "                pass\n",
    "            # create dimension & variable\n",
    "            w_nc_fid.createDimension('num', 1)  \n",
    "            w_nc_fid.createVariable('Tpref', 'f4',('num'))\n",
    "            # write variable\n",
    "            w_nc_fid.variables['Tpref'][:] = tpref_species\n",
    "            w_nc_fid.close()\n",
    "            \n",
    "        #---\n",
    "        # O2threshold\n",
    "        #---\n",
    "        netcdf_name = 'o2thresh_'+species_names[i].replace(' ','_')+'_based_on_monthly_clim_1995_2014.nc'\n",
    "        if not os.path.exists(savepath+netcdf_name):\n",
    "            print('Create file '+savepath+netcdf_name)\n",
    "            w_nc_fid = Dataset(savepath+netcdf_name, 'w', format='NETCDF4_CLASSIC')\n",
    "            w_nc_fid.info = \"o2thresh calculated as 10th percentile from lonxlatxdepth pO2 data in-habitat, volume weighted.\" ;\n",
    "            w_nc_fid.author = \"Cara Nisen & Anne Moree, Nov 2022\" ;\n",
    "            w_nc_fid.reference = \"o2thresh as described in Clarke et al. (2021)\" ;\n",
    "            w_nc_fid.units = \"C\" ;\n",
    "            w_nc_fid.method = \"10th percentile of the field using Python, weighted by volume\" ;\n",
    "            w_nc_fid.source_pO2    = file_pO2\n",
    "            w_nc_fid.source_Tpref    = file_t_insitu\n",
    "            w_nc_fid.script    = '/home/ollie/ncara/scripts/plot_AGI_toothfish_TPref_O2thresh_save_as_netcdf.ipynb'\n",
    "            w_nc_fid.depth_min = depth_min[iii]\n",
    "            w_nc_fid.depth_max = depth_max[iii]\n",
    "            try:\n",
    "                w_nc_fid.LWa  = LWa[iii]\n",
    "                w_nc_fid.LWb  = LWb[iii]\n",
    "                w_nc_fid.Linf = Linf[iii]\n",
    "            except: # the above info is not needed anymore with updated AGI calculation\n",
    "                pass\n",
    "            # create dimension & variable\n",
    "            w_nc_fid.createDimension('num', 1)  \n",
    "            w_nc_fid.createVariable('o2thresh', 'f4',('num'))\n",
    "            # write variable\n",
    "            w_nc_fid.variables['o2thresh'][:] = o2thresh_species\n",
    "            w_nc_fid.close()\n",
    "            \n",
    "        #---\n",
    "        # AGIcrit\n",
    "        #---\n",
    "        netcdf_name = 'AGIcrit_'+species_names[i].replace(' ','_')+'_based_on_monthly_clim_1995_2014.nc'\n",
    "        if not os.path.exists(savepath+netcdf_name):\n",
    "            print('Create file '+savepath+netcdf_name)\n",
    "            w_nc_fid = Dataset(savepath+netcdf_name, 'w', format='NETCDF4_CLASSIC')\n",
    "            w_nc_fid.info = \"AGIcrit calculated as 10th percentile from lonxlatxdepth insitu T data & pO2 in-habitat, volume weighted.\" ;\n",
    "            w_nc_fid.author = \"Cara Nisen & Anne Moree, Nov 2022\" ;\n",
    "            w_nc_fid.reference = \"AGIcrit as described in Clarke et al. (2021)\" ;\n",
    "            w_nc_fid.units = \"C\" ;\n",
    "            w_nc_fid.method = \"10th percentile of the field using Python, weighted by volume\" ;\n",
    "            w_nc_fid.source_pO2    = file_pO2\n",
    "            w_nc_fid.source_Tpref    = file_t_insitu\n",
    "            w_nc_fid.script    = '/home/ollie/ncara/scripts/plot_AGI_toothfish_TPref_O2thresh_save_as_netcdf.ipynb'\n",
    "            w_nc_fid.depth_min = depth_min[iii]\n",
    "            w_nc_fid.depth_max = depth_max[iii]\n",
    "            try:\n",
    "                w_nc_fid.LWa  = LWa[iii]\n",
    "                w_nc_fid.LWb  = LWb[iii]\n",
    "                w_nc_fid.Linf = Linf[iii]\n",
    "            except: # the above info is not needed anymore with updated AGI calculation\n",
    "                pass\n",
    "            # create dimension & variable\n",
    "            w_nc_fid.createDimension('num', 1)  \n",
    "            w_nc_fid.createVariable('AGIcrit', 'f4',('num'))\n",
    "            # write variable\n",
    "            w_nc_fid.variables['AGIcrit'][:] = res[0]\n",
    "            w_nc_fid.close()\n",
    "        print('Saved thresholds for',species_names[i])\n",
    "            \n",
    "    del a1,w_ratio,totalvol_inhabitat,vol_inhabitat_b,vol_inhabitat\n",
    "    del dataout1b,dataout2b,AGI\n",
    "    del dataout1,dataout2\n",
    "    print ('')\n",
    "    \n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
